<!doctype html><html lang=en><head><meta charset=utf-8><meta name=description content="这次课我们开始说计算机视觉任务⾥的主流技术：卷积神经⽹络。
 下⾯是⼀张简笔画图⽚，我知道当你看到这样图⽚的时候能够很快的识别图像⾥⾯是⼀只⼤象。
 有⼈认为，那是因为这张图⾥有两只圆圆⼤⼤的⽿朵、⼀个⻓⻓的⿐⼦、粗壮的四肢和细细的尾巴，在你的经验
 ⾥把这四个特征放到⼀起时，是⼤象⽆疑了。
 机器是不是也可以先识别这些局部特征再综合判断图中的动物类别？答案是肯定的。下⾯的问题就变成如何能够表示这些特征以及如何能够识别这些特征。
 为了解决这个问题，先补充两个知识点：补充1. 图⽚在计算机中的表示⽅式。
 如上图所示，图⽚在机器⾥由很多像素点构成，每个像素点都是取值在`0-255`的数值。当图⽚像上图⼀样是⿊⽩图⽚(灰度图⽚)时，每个像素点由⼀个数值构成，上图⼤⼩就是`1*18*18`；如果图⽚是彩⾊的，每个像素点通常由三个数值构成，分别表示这个点上红绿蓝的强弱，这就是RGB表示⽅式(R-red\G-green\B-blue)。为了理解的更清楚，我们再看下图这个例⼦：
  彩⾊图⽚中，每个像素点上表示红⾊强弱的数值组合成⼀个矩阵，我们管这个矩阵叫做图⽚的⼀个通道，同理，图⽚的绿⾊蓝⾊也会各⾃构成⼀个矩阵，所以这张彩⾊图⽚具有对应RGB的三个通道，上图⼤⼩就是 3*8*6 ( 通道数*⾼*宽)。注意，在⽹络中图⽚的⼤⼩通常和输⼊层的⼤⼩密切相关。"><meta property="og:title" content="机器学习基础作业班 第三周"><meta property="og:description" content="这次课我们开始说计算机视觉任务⾥的主流技术：卷积神经⽹络。
 下⾯是⼀张简笔画图⽚，我知道当你看到这样图⽚的时候能够很快的识别图像⾥⾯是⼀只⼤象。
 有⼈认为，那是因为这张图⾥有两只圆圆⼤⼤的⽿朵、⼀个⻓⻓的⿐⼦、粗壮的四肢和细细的尾巴，在你的经验
 ⾥把这四个特征放到⼀起时，是⼤象⽆疑了。
 机器是不是也可以先识别这些局部特征再综合判断图中的动物类别？答案是肯定的。下⾯的问题就变成如何能够表示这些特征以及如何能够识别这些特征。
 为了解决这个问题，先补充两个知识点：补充1. 图⽚在计算机中的表示⽅式。
 如上图所示，图⽚在机器⾥由很多像素点构成，每个像素点都是取值在`0-255`的数值。当图⽚像上图⼀样是⿊⽩图⽚(灰度图⽚)时，每个像素点由⼀个数值构成，上图⼤⼩就是`1*18*18`；如果图⽚是彩⾊的，每个像素点通常由三个数值构成，分别表示这个点上红绿蓝的强弱，这就是RGB表示⽅式(R-red\G-green\B-blue)。为了理解的更清楚，我们再看下图这个例⼦：
  彩⾊图⽚中，每个像素点上表示红⾊强弱的数值组合成⼀个矩阵，我们管这个矩阵叫做图⽚的⼀个通道，同理，图⽚的绿⾊蓝⾊也会各⾃构成⼀个矩阵，所以这张彩⾊图⽚具有对应RGB的三个通道，上图⼤⼩就是 3*8*6 ( 通道数*⾼*宽)。注意，在⽹络中图⽚的⼤⼩通常和输⼊层的⼤⼩密切相关。"><meta property="og:type" content="website"><meta property="og:image" content="https://www.knowlnk.tech/icon.png"><meta property="og:url" content="https://www.knowlnk.tech/notes/machine_leaning/begin_home_work/%E4%BD%9C%E4%B8%9A%E8%AE%AD%E7%BB%83%E8%90%A5-%E7%AC%AC%E4%B8%89%E5%91%A8/"><meta property="og:width" content="200"><meta property="og:height" content="200"><meta name=twitter:card content="summary"><meta name=twitter:title content="机器学习基础作业班 第三周"><meta name=twitter:description content="这次课我们开始说计算机视觉任务⾥的主流技术：卷积神经⽹络。
 下⾯是⼀张简笔画图⽚，我知道当你看到这样图⽚的时候能够很快的识别图像⾥⾯是⼀只⼤象。
 有⼈认为，那是因为这张图⾥有两只圆圆⼤⼤的⽿朵、⼀个⻓⻓的⿐⼦、粗壮的四肢和细细的尾巴，在你的经验
 ⾥把这四个特征放到⼀起时，是⼤象⽆疑了。
 机器是不是也可以先识别这些局部特征再综合判断图中的动物类别？答案是肯定的。下⾯的问题就变成如何能够表示这些特征以及如何能够识别这些特征。
 为了解决这个问题，先补充两个知识点：补充1. 图⽚在计算机中的表示⽅式。
 如上图所示，图⽚在机器⾥由很多像素点构成，每个像素点都是取值在`0-255`的数值。当图⽚像上图⼀样是⿊⽩图⽚(灰度图⽚)时，每个像素点由⼀个数值构成，上图⼤⼩就是`1*18*18`；如果图⽚是彩⾊的，每个像素点通常由三个数值构成，分别表示这个点上红绿蓝的强弱，这就是RGB表示⽅式(R-red\G-green\B-blue)。为了理解的更清楚，我们再看下图这个例⼦：
  彩⾊图⽚中，每个像素点上表示红⾊强弱的数值组合成⼀个矩阵，我们管这个矩阵叫做图⽚的⼀个通道，同理，图⽚的绿⾊蓝⾊也会各⾃构成⼀个矩阵，所以这张彩⾊图⽚具有对应RGB的三个通道，上图⼤⼩就是 3*8*6 ( 通道数*⾼*宽)。注意，在⽹络中图⽚的⼤⼩通常和输⼊层的⼤⼩密切相关。"><meta name=twitter:image content="https://www.knowlnk.tech/icon.png"><title>机器学习基础作业班 第三周</title><meta name=viewport content="width=device-width,initial-scale=1"><link rel="shortcut icon" type=image/png href=https://www.knowlnk.tech//icon.png><link href=https://www.knowlnk.tech/styles.80333fa2099c0bee674efa435fde378c.min.css rel=stylesheet><link href=https://www.knowlnk.tech/styles/_light_syntax.86a48a52faebeaaf42158b72922b1c90.min.css rel=stylesheet id=theme-link><script src=https://www.knowlnk.tech/js/darkmode.fb33e48379e1030738da955472e32fad.min.js></script>
<script src=https://www.knowlnk.tech/js/util.00639692264b21bc3ee219733d38a8be.min.js></script>
<link rel=preload href=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css as=style onload='this.onload=null,this.rel="stylesheet"' integrity=sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js integrity=sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/contrib/copy-tex.min.js integrity=sha384-ww/583aHhxWkz5DEVn6OKtNiIaLi2iBRNZXfJRiY1Ai7tnJ9UXpEsyvOITVpTl4A crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/npm/@floating-ui/core@1.2.1></script>
<script src=https://cdn.jsdelivr.net/npm/@floating-ui/dom@1.2.1></script>
<script defer src=https://www.knowlnk.tech/js/popover.aa9bc99c7c38d3ae9538f218f1416adb.min.js></script>
<script defer src=https://www.knowlnk.tech/js/code-title.ce4a43f09239a9efb48fee342e8ef2df.min.js></script>
<script defer src=https://www.knowlnk.tech/js/clipboard.2913da76d3cb21c5deaa4bae7da38c9f.min.js></script>
<script defer src=https://www.knowlnk.tech/js/callouts.7723cac461d613d118ee8bb8216b9838.min.js></script>
<script>const SEARCH_ENABLED=!1,LATEX_ENABLED=!0,PRODUCTION=!0,BASE_URL="https://www.knowlnk.tech/",fetchData=Promise.all([fetch("https://www.knowlnk.tech/indices/linkIndex.d6c8376188db408bf8fa89b451143502.min.json").then(e=>e.json()).then(e=>({index:e.index,links:e.links})),fetch("https://www.knowlnk.tech/indices/contentIndex.dc1525c67b49c1ee75637756002da0f2.min.json").then(e=>e.json())]).then(([{index:e,links:t},n])=>({index:e,links:t,content:n})),render=()=>{const e=new URL(BASE_URL),t=e.pathname,n=window.location.pathname,s=t==n;addCopyButtons(),addTitleToCodeBlocks(),addCollapsibleCallouts(),initPopover("https://www.knowlnk.tech",!0);const o=document.getElementById("footer");if(o){const e=document.getElementById("graph-container");if(!e)return requestAnimationFrame(render);e.textContent="";const t=s&&!1;drawGraph("https://www.knowlnk.tech",t,[{"/moc":"#4388cc"}],t?{centerForce:1,depth:-1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.5,linkDistance:1,opacityScale:3,repelForce:1,scale:1.4}:{centerForce:1,depth:1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.6,linkDistance:1,opacityScale:3,repelForce:2,scale:1.2})}var i=document.getElementsByClassName("mermaid");i.length>0&&import("https://unpkg.com/mermaid@9/dist/mermaid.esm.min.mjs").then(e=>{e.default.init()});function a(n){const e=n.target,t=e.className.split(" "),s=t.includes("broken"),o=t.includes("internal-link");plausible("Link Click",{props:{href:e.href,broken:s,internal:o,graph:!1}})}const r=document.querySelectorAll("a");for(link of r)link.className.includes("root-title")&&link.addEventListener("click",a,{once:!0})},init=(e=document)=>{addCopyButtons(),addTitleToCodeBlocks(),renderMathInElement(e.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],macros:{'’':"'"},throwOnError:!1})}</script><script type=module>
    import { attachSPARouting } from "https:\/\/www.knowlnk.tech\/js\/router.d6fe6bd821db9ea97f9aeefae814d8e7.min.js"
    attachSPARouting(init, render)
  </script><script defer data-domain=www.knowlnk.tech src=https://plausible.io/js/script.js></script>
<script>window.plausible=window.plausible||function(){(window.plausible.q=window.plausible.q||[]).push(arguments)}</script></head><body><div id=search-container><div id=search-space><input autocomplete=off id=search-bar name=search type=text aria-label=Search placeholder="Search for something..."><div id=results-container></div></div></div><script src=https://cdn.jsdelivr.net/npm/flexsearch@0.7.21/dist/flexsearch.bundle.js integrity="sha256-i3A0NZGkhsKjVMzFxv3ksk0DZh3aXqu0l49Bbh0MdjE=" crossorigin=anonymous defer></script>
<script defer src=https://www.knowlnk.tech/js/full-text-search.e6e2e0c213187ca0c703d6e2c7a77fcd.min.js></script><div class=singlePage><header><h1 id=page-title><a class=root-title href=https://www.knowlnk.tech/>寻剑之路</a></h1><div class=spacer></div><div id=search-icon><p>Search</p><svg tabindex="0" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search Icon</title><desc id="desc">Icon to open search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"/><circle cx="8" cy="8" r="7"/></g></svg></div><div class=darkmode><input class=toggle id=darkmode-toggle type=checkbox tabindex=-1>
<label id=toggle-label-light for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="dayIcon" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35"><title>Light Mode</title><path d="M6 17.5C6 16.672 5.328 16 4.5 16h-3C.672 16 0 16.672.0 17.5S.672 19 1.5 19h3C5.328 19 6 18.328 6 17.5zM7.5 26c-.414.0-.789.168-1.061.439l-2 2C4.168 28.711 4 29.086 4 29.5 4 30.328 4.671 31 5.5 31c.414.0.789-.168 1.06-.44l2-2C8.832 28.289 9 27.914 9 27.5 9 26.672 8.329 26 7.5 26zm10-20C18.329 6 19 5.328 19 4.5v-3C19 .672 18.329.0 17.5.0S16 .672 16 1.5v3C16 5.328 16.671 6 17.5 6zm10 3c.414.0.789-.168 1.06-.439l2-2C30.832 6.289 31 5.914 31 5.5 31 4.672 30.329 4 29.5 4c-.414.0-.789.168-1.061.44l-2 2C26.168 6.711 26 7.086 26 7.5 26 8.328 26.671 9 27.5 9zM6.439 8.561C6.711 8.832 7.086 9 7.5 9 8.328 9 9 8.328 9 7.5c0-.414-.168-.789-.439-1.061l-2-2C6.289 4.168 5.914 4 5.5 4 4.672 4 4 4.672 4 5.5c0 .414.168.789.439 1.06l2 2.001zM33.5 16h-3c-.828.0-1.5.672-1.5 1.5s.672 1.5 1.5 1.5h3c.828.0 1.5-.672 1.5-1.5S34.328 16 33.5 16zM28.561 26.439C28.289 26.168 27.914 26 27.5 26c-.828.0-1.5.672-1.5 1.5.0.414.168.789.439 1.06l2 2C28.711 30.832 29.086 31 29.5 31c.828.0 1.5-.672 1.5-1.5.0-.414-.168-.789-.439-1.061l-2-2zM17.5 29c-.829.0-1.5.672-1.5 1.5v3c0 .828.671 1.5 1.5 1.5s1.5-.672 1.5-1.5v-3C19 29.672 18.329 29 17.5 29zm0-22C11.71 7 7 11.71 7 17.5S11.71 28 17.5 28 28 23.29 28 17.5 23.29 7 17.5 7zm0 18c-4.136.0-7.5-3.364-7.5-7.5s3.364-7.5 7.5-7.5 7.5 3.364 7.5 7.5S21.636 25 17.5 25z"/></svg></label><label id=toggle-label-dark for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="nightIcon" viewBox="0 0 100 100" style="enable-background='new 0 0 100 100'"><title>Dark Mode</title><path d="M96.76 66.458c-.853-.852-2.15-1.064-3.23-.534-6.063 2.991-12.858 4.571-19.655 4.571C62.022 70.495 50.88 65.88 42.5 57.5 29.043 44.043 25.658 23.536 34.076 6.47c.532-1.08.318-2.379-.534-3.23-.851-.852-2.15-1.064-3.23-.534-4.918 2.427-9.375 5.619-13.246 9.491-9.447 9.447-14.65 22.008-14.65 35.369.0 13.36 5.203 25.921 14.65 35.368s22.008 14.65 35.368 14.65c13.361.0 25.921-5.203 35.369-14.65 3.872-3.871 7.064-8.328 9.491-13.246C97.826 68.608 97.611 67.309 96.76 66.458z"/></svg></label></div></header><article><h1>机器学习基础作业班 第三周</h1><p class=meta>Last updated
Unknown
<a href=https://github.com/rootyue/myblog/tree/hugo/content/notes/machine_leaning/begin_home_work/%e4%bd%9c%e4%b8%9a%e8%ae%ad%e7%bb%83%e8%90%a5%20%e7%ac%ac%e4%b8%89%e5%91%a8.md rel=noopener>Edit Source</a></p><ul class=tags><li><a href=https://www.knowlnk.tech/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/>机器学习</a></li></ul><aside class=mainTOC><details><summary>Table of Contents</summary><nav id=TableOfContents><ol><li><ol><li><a href=#以上图为例如果要识别脸通常会先去识别些更的特征如上例最底图中各种边为什么可以这样做这样做有什么好处> 以上图为例，如果要识别⼈脸通常会先去识别⼀些更⼩的特征，⽐如上例最底图中各种"边"，①为什么可以这样做？这样做有什么好处？</a></li><li><a href=#按照上的计算法将图2与边1进计算的计算结果应该是>②按照上⾯的计算⽅法，将"⼦图2"与"边1"进⾏计算的计算结果应该是？</a></li><li><a href=#将这两个计算结果对你会发现什么这说明什么>③将这两个计算结果对⽐，你会发现什么？这说明什么？</a></li><li><a href=#参考我的视频卷积神经络cnn卷积过程理解卷积神经络中卷积的过程具体是怎样的>④参考我的视频"卷积神经⽹络(CNN)卷积过程"，理解卷积神经⽹络中"卷积"的过程具体是怎样的？</a></li><li><a href=#视频中选的步为1如果步为2有什么意义>⑤视频中选⽤的步⻓为1，如果步⻓为2，有什么意义？</a></li><li><a href=#观察上例特征图特征图和边1是什么关系如何理解特征图>⑥观察上例"特征图"，"特征图"和"边1"是什么关系？如何理解"特征图"？</a></li><li><a href=#resbegin_home_workweek3image12png卷积核的数量和特征图通道数间有什么关系注意卷积核也是可以多个通道的如下图> <img src=res/begin_home_work/week3/image12.png alt>⑦卷积核的数量和特征图"通道数"间有什么关系？注意：卷积核也是可以多个通道的，如下图：</a></li><li><a href=#请你的理解解释上图>⑧请⽤你的理解解释上图。</a></li><li><a href=#如果希望对彩图rgb进卷积后得到多个通道的特征图需要怎么做>⑨如果希望对彩⾊图⽚(RGB)进⾏"卷积"后得到多个通道的特征图，需要怎么做？</a></li><li><a href=#假如有张为12px12px的png图2个33的卷积核处理在步为1的情况下得到的特征图形状为注意应当表示为通道数宽->⑩假如有⼀张⼤⼩为12px*12px⼤⼩的png图⽚，⽤2个3*3⼤⼩的卷积核处理，在步⻓为1的情况下，得到的特征图形状(⼤⼩)为？(注意:应当表示为"通道数*⾼*宽 ")</a></li><li><a href=#请总结输图的通道数卷积核的通道数卷积核的数量和输出特征图的通道数之间是怎样的关系>⑪请总结输⼊图⽚的通道数、卷积核的通道数、卷积核的数量和输出特征图的通道数之间是怎样的关系。</a></li><li><a href=#经常会在卷积之后加上池化操作池化的意义是什么>⑫经常会在卷积之后加上"池化"操作，"池化"的意义是什么？</a></li><li><a href=#常到的池化有最池化和平均池化请举例说明分别如何计算>⑬常⻅到的池化有"最⼤池化"和"平均池化"，请举例说明分别如何计算。</a></li><li><a href=#在卷积和池化的时候经常先给图进填充常到的填充式有哪些填充的意义是什么>⑭在卷积和池化的时候经常先给图⽚进⾏"填充"，常⻅到的填充⽅式有哪些？填充的意义是什么？</a></li><li><a href=#输图宽输出特征图宽卷积核宽步和填充之间有怎样的关系>⑮输⼊图⽚⾼宽、输出特征图⾼宽、卷积核⾼宽、步⻓和填充⼤⼩之间有怎样的关系？</a></li><li><a href=#如何理解卷积过程中的平移不变性>⑯如何理解卷积过程中的"平移不变性"？</a></li><li><a href=#为什么说卷积神经络是稀疏连接的>⑰为什么说卷积神经⽹络是"稀疏连接"的？</a></li><li><a href=#如何理解卷积过程中的参数共享>⑱如何理解卷积过程中的"参数共享"？</a></li><li><a href=#-如果卷积核是代表的图中局部小特征那么如何找到这里面的填充值>⑲ 如果卷积核是代表的图中局部小特征，那么如何找到这里面的填充值？</a></li><li><a href=#-在今天学习的内容里面哪些是在卷积神经网络里的超参数>⑳ 在今天学习的内容里面，哪些是在卷积神经网络里的超参数？</a></li><li><a href=#请你看图解释这个络的设计别着急查资料先读图试试都是我们学习过的内容>㉑请你看图解释这个⽹络的设计(别着急查资料，先⾃⼰读图试试，都是我们学习过的内容)。</a></li><li><a href=#读懂络结构图之后就代码去实现吧像搭积样把对应的功能封装成函数后拼装在起这到了全连接层卷积层和池化层和激活函数我们之前定义过激活函数你完全可以实现个卷积函数和个池化函数选做当然这只是为了练习和学习通常使时会直接调框架中给我们提供的接>读懂⽹络结构图之后，就⽤代码去实现吧，像搭积⽊⼀样，把对应的功能封装成函数后拼装在⼀起，这⾥⾯⽤到了全连接层、卷积层和池化层和激活函数。我们之前定义过激活函数，㉒你完全可以⾃⼰实现⼀个卷积函数和⼀个池化函数（选做）。当然，这只是为了练习和学习，通常使⽤时会直接调⽤框架中给我们提供的接⼝。</a></li><li><a href=#pytorch中的卷积层和池化层应当如何调函数实现如何设置窗填充和步>㉓PyTorch中的卷积层和池化层应当如何调⽤函数实现？如何设置窗⼝⼤⼩、填充和步⻓？</a></li><li><a href=#组件都会了你可以尝试使pytorch将这个lenet络的定义实现>㉔组件都会⽤了，你可以尝试使⽤PyTorch将这个LeNet⽹络的定义实现。</a></li><li><a href=#最后补充个常重要的知识点1--1卷积核没错就是宽和的值都为1的卷积核1--1卷积核的使能解决哪些问题> 最后补充⼀个⾮常重要的知识点："1 * 1卷积核"，没错，就是宽和⾼的值都为1的卷积核。㉕"1 * 1卷积核"的使⽤能解决哪些问题？</a></li></ol></li></ol></nav></details></aside><p>这次课我们开始说计算机视觉任务⾥的主流技术：卷积神经⽹络。</p><p> 
<img src=https://www.knowlnk.tech//res/begin_home_work/week3/image1.png width=auto alt>下⾯是⼀张简笔画图⽚，我知道当你看到这样图⽚的时候能够很快的识别图像⾥⾯是⼀只⼤象。</p><p> 有⼈认为，那是因为这张图⾥有两只圆圆⼤⼤的⽿朵、⼀个⻓⻓的⿐⼦、粗壮的四肢和细细的尾巴，在你的经验</p><p> ⾥把这四个特征放到⼀起时，是⼤象⽆疑了。</p><p> 机器是不是也可以先识别这些局部特征再综合判断图中的动物类别？答案是肯定的。下⾯的问题就变成如何能够表示这些特征以及如何能够识别这些特征。</p><p> 为了解决这个问题，先补充两个知识点：补充1. 图⽚在计算机中的表示⽅式。</p><p><img src=https://www.knowlnk.tech//res/begin_home_work/week3/image2.png width=auto alt></p><p>如上图所示，图⽚在机器⾥由很多像素点构成，每个像素点都是取值在`0-255`的数值。当图⽚像上图⼀样是⿊⽩图⽚(灰度图⽚)时，每个像素点由⼀个数值构成，上图⼤⼩就是`1*18*18`；如果图⽚是彩⾊的，每个像素点通常由三个数值构成，分别表示这个点上红绿蓝的强弱，这就是RGB表示⽅式(R-red\G-green\B-blue)。为了理解的更清楚，我们再看下图这个例⼦：</p><p> 
<img src=https://www.knowlnk.tech//res/begin_home_work/week3/image3.png width=auto alt></p><p> 彩⾊图⽚中，每个像素点上表示红⾊强弱的数值组合成⼀个矩阵，我们管这个矩阵叫做图⽚的⼀个通道，同理，图⽚的绿⾊蓝⾊也会各⾃构成⼀个矩阵，所以这张彩⾊图⽚具有对应RGB的三个通道，上图⼤⼩就是 3*8*6 ( 通道数*⾼*宽)。注意，在⽹络中图⽚的⼤⼩通常和输⼊层的⼤⼩密切相关。</p><p> 补充2. 图⽚中的特征构成。</p><p><img src=https://www.knowlnk.tech//res/begin_home_work/week3/image4.jpeg width=auto alt></p><a href=#以上图为例如果要识别脸通常会先去识别些更的特征如上例最底图中各种边为什么可以这样做这样做有什么好处><h3 id=以上图为例如果要识别脸通常会先去识别些更的特征如上例最底图中各种边为什么可以这样做这样做有什么好处><span class=hanchor arialabel=Anchor># </span> 以上图为例，如果要识别⼈脸通常会先去识别⼀些更⼩的特征，⽐如上例最底图中各种"边"，①为什么可以这样做？这样做有什么好处？</h3></a><blockquote><p>可以这样子做是因为物体的一些基本特征具有很好的区分度和稳定性。而这样子做的好处是可以提高识别的准确性，将复杂的问题分而治之，降低计算量。</p></blockquote><p>所以现在问题换为在图中识别⼩特征：</p><p>&ldquo;边1&rdquo;：
 
<img src=https://www.knowlnk.tech//res/begin_home_work/week3/image5.png width=auto alt></p><p> 根据上⾯补充1中内容，&ldquo;边1"对应矩阵信息表示为：</p><p> 
<img src=https://www.knowlnk.tech//res/begin_home_work/week3/image6.png width=auto alt></p><p> 
<img src=https://www.knowlnk.tech//res/begin_home_work/week3/image7.png width=auto alt>现在特征的表示已经有了，如何在图⽚中来识别这些特征？这就是我们⽤的"卷积"过程了。现在我在图中找到两个⼦图，"⼦图1"以及对应矩阵信息表示为：</p><p> 
<img src=https://www.knowlnk.tech//res/begin_home_work/week3/image8.png width=auto alt>为了表示"⼦图1"是否是"边1"要找的特征，我们进⾏这样的计算：</p><p> 这⾥的"44500"是计算的结果。 &ldquo;⼦图2"以及对应矩阵信息表示为：</p><p><img src=https://www.knowlnk.tech//res/begin_home_work/week3/image9.png width=auto alt></p><a href=#按照上的计算法将图2与边1进计算的计算结果应该是><h3 id=按照上的计算法将图2与边1进计算的计算结果应该是><span class=hanchor arialabel=Anchor># </span>②按照上⾯的计算⽅法，将"⼦图2"与"边1"进⾏计算的计算结果应该是？</h3></a><blockquote><p>30 x 100+100 x 100=3000+10000=13000</p></blockquote><a href=#将这两个计算结果对你会发现什么这说明什么><h3 id=将这两个计算结果对你会发现什么这说明什么><span class=hanchor arialabel=Anchor># </span>③将这两个计算结果对⽐，你会发现什么？这说明什么？</h3></a><blockquote><p>44500 > 13000 说明子图1比子图2有更大的可能性为边”1”</p></blockquote><a href=#参考我的视频卷积神经络cnn卷积过程理解卷积神经络中卷积的过程具体是怎样的><h3 id=参考我的视频卷积神经络cnn卷积过程理解卷积神经络中卷积的过程具体是怎样的><span class=hanchor arialabel=Anchor># </span>④参考我的视频"卷积神经⽹络(CNN)卷积过程"，理解卷积神经⽹络中"卷积"的过程具体是怎样的？</h3></a><p>在卷积神经网络(Convolutional Neural Network, CNN)中，卷积运算是一种重要的图像处理操作，用于提取输入数据中的特征信息。下面具体介绍卷积过程：</p><ol><li>首先确定卷积核的大小和深度(即通道数)，通常是一个小矩阵，如3x3或5x5。卷积核的深度等于输入数据的深度。</li><li>将卷积核从输入数据的最左上角位置开始，按照步长(stride)进行滑动，在每个位置上执行卷积运算。</li><li>在每个位置上，将卷积核与输入数据的对应部分进行逐元素相乘，并将结果相加得到输出特征图上该位置的值。</li><li>重复2-3步骤，直到卷积核滑动完整个输入数据，生成了一个新的输出特征图。</li></ol><a href=#视频中选的步为1如果步为2有什么意义><h3 id=视频中选的步为1如果步为2有什么意义><span class=hanchor arialabel=Anchor># </span>⑤视频中选⽤的步⻓为1，如果步⻓为2，有什么意义？</h3></a><blockquote><p>步长为1时，卷积核每次沿着输入数据的水平和垂直方向分别移动一个像素。这种方式可以捕获输入数据中更细小的特征，但会生成更大尺寸和更高分辨率的输出特征图。</p><p>步长为2时，卷积核每次沿着输入数据的水平和垂直方向分别移动两个像素，跳过了一部分输入数据。这种方式可以减少输出特征图的尺寸和分辨率，从而降低模型的计算复杂度，并且可以增强模型的泛化性能。</p></blockquote><p>按照这个"卷积"过程，由"边1"按照步⻓为1在原图中进⾏计算，将计算结果拼成的矩阵叫做"特征图"，那么
"边1"对应的特征图如下：</p><p> 
<img src=https://www.knowlnk.tech//res/begin_home_work/week3/image10.png width=auto alt></p><a href=#观察上例特征图特征图和边1是什么关系如何理解特征图><h3 id=观察上例特征图特征图和边1是什么关系如何理解特征图><span class=hanchor arialabel=Anchor># </span>⑥观察上例"特征图"，"特征图"和"边1"是什么关系？如何理解"特征图"？</h3></a><blockquote><p>特征图就是”边1”在滑动的过程中对应位置上的可能性。而”特征图”就是经过卷积核操作后提取出来的更高层次的特征表示，每一个特征图都对应着一组卷积核的输出结果。</p></blockquote><p> 
<img src=https://www.knowlnk.tech//res/begin_home_work/week3/image11.png width=auto alt>如果现在有"边1"、"边2"和"边3"，就会得到三个"特征图"(如下图)，通常为了表述清楚我们说这⾥得到的是⼀个"特征图"，⼀个具有三通道的"特征图"(只是我个⼈的表述习惯)。</p><p> 像这⾥的"边1"这样⽤来表示某个"特征"的元素就是"卷积核"。</p><h3 id=resbegin_home_workweek3image12png卷积核的数量和特征图通道数间有什么关系注意卷积核也是可以多个通道的如下图> 
<img src=https://www.knowlnk.tech//res/begin_home_work/week3/image12.png width=auto alt>⑦卷积核的数量和特征图"通道数"间有什么关系？注意：卷积核也是可以多个通道的，如下图：</h3><blockquote><p>卷积核的数量和特征图的”通道数”是保持一致的</p></blockquote><p>这⾥是⼀个卷积核，⼀个具有三通道的卷积核，最终获得了⼀个通道的特征图。</p><a href=#请你的理解解释上图><h3 id=请你的理解解释上图><span class=hanchor arialabel=Anchor># </span>⑧请⽤你的理解解释上图。</h3></a><blockquote><p>原图有三个通道的数据，使用了具有三个通道的卷积核，每一个通道的数据使用了对应层的卷积核进行操作分别得到对应的临时特征图，而这3个临时特征图可以合并为一个具有3通道的特征图。</p></blockquote><a href=#如果希望对彩图rgb进卷积后得到多个通道的特征图需要怎么做><h3 id=如果希望对彩图rgb进卷积后得到多个通道的特征图需要怎么做><span class=hanchor arialabel=Anchor># </span>⑨如果希望对彩⾊图⽚(RGB)进⾏"卷积"后得到多个通道的特征图，需要怎么做？</h3></a><blockquote><p>可以对其应用多通道的卷积核进行操作</p></blockquote><a href=#假如有张为12px12px的png图2个33的卷积核处理在步为1的情况下得到的特征图形状为注意应当表示为通道数宽-><h3 id=假如有张为12px12px的png图2个33的卷积核处理在步为1的情况下得到的特征图形状为注意应当表示为通道数宽-><span class=hanchor arialabel=Anchor># </span>⑩假如有⼀张⼤⼩为12px*12px⼤⼩的png图⽚，⽤2个3*3⼤⼩的卷积核处理，在步⻓为1的情况下，得到的特征图形状(⼤⼩)为？(注意:应当表示为"通道数*⾼*宽 ")</h3></a><blockquote><p>2 x 10 x10</p></blockquote><a href=#请总结输图的通道数卷积核的通道数卷积核的数量和输出特征图的通道数之间是怎样的关系><h3 id=请总结输图的通道数卷积核的通道数卷积核的数量和输出特征图的通道数之间是怎样的关系><span class=hanchor arialabel=Anchor># </span>⑪请总结输⼊图⽚的通道数、卷积核的通道数、卷积核的数量和输出特征图的通道数之间是怎样的关系。</h3></a><blockquote><p>输入图片的通道数和卷积核的通道数保持一致，卷积核的数量和输出特征图的通道数保持一致</p></blockquote><a href=#经常会在卷积之后加上池化操作池化的意义是什么><h3 id=经常会在卷积之后加上池化操作池化的意义是什么><span class=hanchor arialabel=Anchor># </span>⑫经常会在卷积之后加上"池化"操作，"池化"的意义是什么？</h3></a><blockquote><p>池化操作就是一个没有可习得的参数的卷积核操作，池化的意义就是可以进行下采样</p></blockquote><a href=#常到的池化有最池化和平均池化请举例说明分别如何计算><h3 id=常到的池化有最池化和平均池化请举例说明分别如何计算><span class=hanchor arialabel=Anchor># </span>⑬常⻅到的池化有"最⼤池化"和"平均池化"，请举例说明分别如何计算。</h3></a><p>“最大池化”在当前卷积核大小中取的当前区域范围内的最大值，而 “平均池化” 则是求得当前范围内的平均值。</p><p>池化层的步长(stride)决定了池化窗口在输入数据上移动的距离。最大池化(Max Pooling)和平均池化(Average Pooling)的滑动步长都可以是任意正整数，但通常选择的步长为池化窗口的大小的一半，即 $stride = \frac{pool_size}{2}$。</p><p>这样的步长选择有以下原因：</p><ol><li>保证没有重叠区域：使用步长为池化窗口大小的一半，可以确保每个池化窗口之间不存在重叠区域，避免了类似于卷积操作中的局部重叠现象，从而减少输出特征图的尺寸和计算量。</li><li>避免信息丢失：使用过大的步长会使得池化操作忽略一些重要的特征信息，从而影响模型的性能和鲁棒性。使用步长为池化窗口大小的一半，可以保证池化操作不会过于粗略，同时也不会过度压缩特征信息。</li></ol><a href=#在卷积和池化的时候经常先给图进填充常到的填充式有哪些填充的意义是什么><h3 id=在卷积和池化的时候经常先给图进填充常到的填充式有哪些填充的意义是什么><span class=hanchor arialabel=Anchor># </span>⑭在卷积和池化的时候经常先给图⽚进⾏"填充"，常⻅到的填充⽅式有哪些？填充的意义是什么？</h3></a><p>在卷积神经网络(Convolutional Neural Network, CNN)中，卷积和池化操作通常都需要将输入数据进行填充(padding)，以控制输出特征图的尺寸、边缘效应等。下面是一些常见的填充方式及其意义：</p><ol><li>零填充(Zero Padding)：零填充是最常用的一种填充方式，在输入数据的周围添加一圈值为0的像素，使得原始输入数据和填充后的数据尺寸相同。零填充的主要作用是保持输入数据的空间大小不变，并且可以减少边缘效应的影响，从而提高模型的准确性和鲁棒性。</li><li>边界填充(Border Padding)：边界填充是在输入数据的四周添加与边缘颜色相同的像素，一般情况下会使用黑色或白色像素进行填充。这种填充方式可以避免由于零填充引入的额外噪声和干扰，但同时也会导致输出特征图的尺寸比输入数据更小。</li><li>反射填充(Reflect Padding)：反射填充是在输入数据的边缘上按照对称镜像的方式添加像素，使得输入数据和输出数据具有相同的尺寸和形状。反射填充可以有效地避免边缘效应，并且可以保留输入数据的平滑性和连续性，从而提高模型的稳定性和可靠性。</li><li>复制填充(Copy Padding)：复制填充是将输入数据的边缘像素复制若干次，使得输入数据和填充后的数据具有相同的尺寸。这种填充方式可以避免边缘效应，但同时也可能会引入额外的重复信息和噪声，从而影响模型的性能和鲁棒性。</li></ol><p>填充的主要作用是控制输出特征图的尺寸，比如说可以保持处理后的特征图和原图的尺寸一致。</p><a href=#输图宽输出特征图宽卷积核宽步和填充之间有怎样的关系><h3 id=输图宽输出特征图宽卷积核宽步和填充之间有怎样的关系><span class=hanchor arialabel=Anchor># </span>⑮输⼊图⽚⾼宽、输出特征图⾼宽、卷积核⾼宽、步⻓和填充⼤⼩之间有怎样的关系？</h3></a><p>out_height = (input_height + 2 x padding_height - kernel_height) / stride + 1
out_width = (input_width + 2 x padding_width - kernel_width) / stride + 1</p><p>现在，你已经对卷积神经⽹络⾥⾯的基本概念有所了解，可以尝试思考回答以下较为深⼊的问题。</p><a href=#如何理解卷积过程中的平移不变性><h3 id=如何理解卷积过程中的平移不变性><span class=hanchor arialabel=Anchor># </span>⑯如何理解卷积过程中的"平移不变性"？</h3></a><blockquote><p>“平移不变性”指在进行卷积核操作的时候是进行滑动计算的，所以就算特征发生了平移的情况也可以找到对应的特征。</p></blockquote><a href=#为什么说卷积神经络是稀疏连接的><h3 id=为什么说卷积神经络是稀疏连接的><span class=hanchor arialabel=Anchor># </span>⑰为什么说卷积神经⽹络是"稀疏连接"的？</h3></a><blockquote><p>因为卷积核进行计算的时候是进行滑动且一一对应的，所以对应到神经网络节点的连接上去就是稀疏的</p></blockquote><a href=#如何理解卷积过程中的参数共享><h3 id=如何理解卷积过程中的参数共享><span class=hanchor arialabel=Anchor># </span>⑱如何理解卷积过程中的"参数共享"？</h3></a><blockquote><p>卷积神经网络在进行连接的时候是稀疏连接的，而卷积核操作需要使用固定的卷积核参数进行计算，所以卷积核上的位置对应的连接权重是相同的，这个就是”参数共享”</p></blockquote><p>最最最最最最最最最最最最最重要的问题来了：</p><p><img src=https://www.knowlnk.tech//res/begin_home_work/week3/image13.png width=auto alt></p><p>别告诉我你没⻅过，这是LeNet⽹络结构图，是卷积神经⽹络的⿐祖。</p><a href=#-如果卷积核是代表的图中局部小特征那么如何找到这里面的填充值><h3 id=-如果卷积核是代表的图中局部小特征那么如何找到这里面的填充值><span class=hanchor arialabel=Anchor># </span>⑲ 如果卷积核是代表的图中局部小特征，那么如何找到这里面的填充值？</h3></a><blockquote><p>这部分的填充值是需要在投喂数据的时候进行训练的，是网络自己习得的。</p></blockquote><a href=#-在今天学习的内容里面哪些是在卷积神经网络里的超参数><h3 id=-在今天学习的内容里面哪些是在卷积神经网络里的超参数><span class=hanchor arialabel=Anchor># </span>⑳ 在今天学习的内容里面，哪些是在卷积神经网络里的超参数？</h3></a><blockquote><p>超参数是网络自身无法习得的参数，比如说网络的连接结构，卷积核的大小，卷积核操作时的步长以及填充方式和大小。</p></blockquote><a href=#请你看图解释这个络的设计别着急查资料先读图试试都是我们学习过的内容><h3 id=请你看图解释这个络的设计别着急查资料先读图试试都是我们学习过的内容><span class=hanchor arialabel=Anchor># </span>㉑请你看图解释这个⽹络的设计(别着急查资料，先⾃⼰读图试试，都是我们学习过的内容)。</h3></a><blockquote><p>先是32x32的图片输入，经过一次卷积核操作（6@5x5）得到6@28x28的特征图，再进行一次池化操作（下采样，卷积核为 6@2x2）得到6@14x14特征图，在进行一次卷积核操作（16@5x5）得到16@10x10的特征图，再进行一次池化操作（下采样，卷积核为16@6x6）得到16@5x5的特征图，然后展开通过一层全连接达到C5，一次全连接达到F6，最后使用softmax分类器进行多分类，输出概率最大的类别</p></blockquote><a href=#读懂络结构图之后就代码去实现吧像搭积样把对应的功能封装成函数后拼装在起这到了全连接层卷积层和池化层和激活函数我们之前定义过激活函数你完全可以实现个卷积函数和个池化函数选做当然这只是为了练习和学习通常使时会直接调框架中给我们提供的接><h3 id=读懂络结构图之后就代码去实现吧像搭积样把对应的功能封装成函数后拼装在起这到了全连接层卷积层和池化层和激活函数我们之前定义过激活函数你完全可以实现个卷积函数和个池化函数选做当然这只是为了练习和学习通常使时会直接调框架中给我们提供的接><span class=hanchor arialabel=Anchor># </span>读懂⽹络结构图之后，就⽤代码去实现吧，像搭积⽊⼀样，把对应的功能封装成函数后拼装在⼀起，这⾥⾯⽤到了全连接层、卷积层和池化层和激活函数。我们之前定义过激活函数，㉒你完全可以⾃⼰实现⼀个卷积函数和⼀个池化函数（选做）。当然，这只是为了练习和学习，通常使⽤时会直接调⽤框架中给我们提供的接⼝。</h3></a><p> </p><a href=#pytorch中的卷积层和池化层应当如何调函数实现如何设置窗填充和步><h3 id=pytorch中的卷积层和池化层应当如何调函数实现如何设置窗填充和步><span class=hanchor arialabel=Anchor># </span>㉓PyTorch中的卷积层和池化层应当如何调⽤函数实现？如何设置窗⼝⼤⼩、填充和步⻓？</h3></a><p>在PyTorch中，可以使用torch.nn模块中的Conv2d和MaxPool2d类来实现卷积层和池化层，具体的调用方法如下：</p><ol><li>Conv2d函数的调用方法：</li></ol><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch.nn</span> <span class=k>as</span> <span class=nn>nn</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 定义一个卷积层，输入特征图通道数为in_channels，输出特征图通道数为out_channels，卷积核大小为kernel_size，步长为stride，填充方式为padding</span>
</span></span><span class=line><span class=cl><span class=n>conv_layer</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=n>in_channels</span><span class=p>,</span> <span class=n>out_channels</span><span class=p>,</span> <span class=n>kernel_size</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=n>stride</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=n>padding</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><ol start=2><li>MaxPool2d函数的调用方法：</li></ol><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch.nn</span> <span class=k>as</span> <span class=nn>nn</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 定义一个池化层，窗口大小为kernel_size，步长为stride，填充方式为padding</span>
</span></span><span class=line><span class=cl><span class=n>pool_layer</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>MaxPool2d</span><span class=p>(</span><span class=n>kernel_size</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=n>stride</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=n>padding</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>其中，in_channels和out_channels分别表示输入和输出特征图的通道数；kernel_size表示卷积核或池化窗口的大小；stride表示卷积或池化操作时在输入数据上移动的步长；padding表示在输入数据周围添加的额外像素。</p><p>例如，可以定义一个卷积层，它的输入特征图通道数为3，输出特征图通道数为16，卷积核大小为3x3，步长为1，填充方式为1，代码如下：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch.nn</span> <span class=k>as</span> <span class=nn>nn</span>
</span></span><span class=line><span class=cl><span class=n>conv_layer</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=n>kernel_size</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>也可以定义一个最大池化层，它的窗口大小为2x2，步长为2，填充方式为0，代码如下：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch.nn</span> <span class=k>as</span> <span class=nn>nn</span>
</span></span><span class=line><span class=cl><span class=n>pool_layer</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>MaxPool2d</span><span class=p>(</span><span class=n>kernel_size</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>通过这些方法可以轻松地实现卷积和池化操作，并且可以根据需要设置窗口大小、填充和步长等超参数。</p><a href=#组件都会了你可以尝试使pytorch将这个lenet络的定义实现><h3 id=组件都会了你可以尝试使pytorch将这个lenet络的定义实现><span class=hanchor arialabel=Anchor># </span>㉔组件都会⽤了，你可以尝试使⽤PyTorch将这个LeNet⽹络的定义实现。</h3></a><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span><span class=lnt>50
</span><span class=lnt>51
</span><span class=lnt>52
</span><span class=lnt>53
</span><span class=lnt>54
</span><span class=lnt>55
</span><span class=lnt>56
</span><span class=lnt>57
</span><span class=lnt>58
</span><span class=lnt>59
</span><span class=lnt>60
</span><span class=lnt>61
</span><span class=lnt>62
</span><span class=lnt>63
</span><span class=lnt>64
</span><span class=lnt>65
</span><span class=lnt>66
</span><span class=lnt>67
</span><span class=lnt>68
</span><span class=lnt>69
</span><span class=lnt>70
</span><span class=lnt>71
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch.nn</span> <span class=k>as</span> <span class=nn>nn</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torchvision</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torchvision.transforms</span> <span class=k>as</span> <span class=nn>transforms</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 定义LeNet模型</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>LeNet</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>(</span><span class=n>LeNet</span><span class=p>,</span> <span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>conv1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=n>kernel_size</span><span class=o>=</span><span class=mi>5</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>sigm1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sigmoid</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>pool1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>AvgPool2d</span><span class=p>(</span><span class=n>kernel_size</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>conv2</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=mi>6</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=n>kernel_size</span><span class=o>=</span><span class=mi>5</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>sigm2</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sigmoid</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>pool2</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>AvgPool2d</span><span class=p>(</span><span class=n>kernel_size</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>fc1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>16</span> <span class=o>*</span> <span class=mi>5</span> <span class=o>*</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>120</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>sigm3</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sigmoid</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>fc2</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>120</span><span class=p>,</span> <span class=mi>84</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>sigm4</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sigmoid</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>fc3</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>84</span><span class=p>,</span> <span class=mi>10</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>pool1</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>sigm1</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>conv1</span><span class=p>(</span><span class=n>x</span><span class=p>)))</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>pool2</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>sigm2</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>conv2</span><span class=p>(</span><span class=n>x</span><span class=p>)))</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=n>x</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>16</span> <span class=o>*</span> <span class=mi>5</span> <span class=o>*</span> <span class=mi>5</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>sigm3</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>fc1</span><span class=p>(</span><span class=n>x</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>sigm4</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>fc2</span><span class=p>(</span><span class=n>x</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>fc3</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>x</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 加载MNIST数据集</span>
</span></span><span class=line><span class=cl><span class=n>transform</span> <span class=o>=</span> <span class=n>transforms</span><span class=o>.</span><span class=n>Compose</span><span class=p>([</span><span class=n>transforms</span><span class=o>.</span><span class=n>ToTensor</span><span class=p>(),</span> <span class=n>transforms</span><span class=o>.</span><span class=n>Normalize</span><span class=p>((</span><span class=mf>0.1307</span><span class=p>,),</span> <span class=p>(</span><span class=mf>0.3081</span><span class=p>,))])</span>
</span></span><span class=line><span class=cl><span class=n>train_dataset</span> <span class=o>=</span> <span class=n>torchvision</span><span class=o>.</span><span class=n>datasets</span><span class=o>.</span><span class=n>MNIST</span><span class=p>(</span><span class=n>root</span><span class=o>=</span><span class=s1>&#39;./data&#39;</span><span class=p>,</span> <span class=n>train</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>download</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>transform</span><span class=o>=</span><span class=n>transform</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>test_dataset</span> <span class=o>=</span> <span class=n>torchvision</span><span class=o>.</span><span class=n>datasets</span><span class=o>.</span><span class=n>MNIST</span><span class=p>(</span><span class=n>root</span><span class=o>=</span><span class=s1>&#39;./data&#39;</span><span class=p>,</span> <span class=n>train</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> <span class=n>download</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>transform</span><span class=o>=</span><span class=n>transform</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>train_loader</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>DataLoader</span><span class=p>(</span><span class=n>train_dataset</span><span class=p>,</span> <span class=n>batch_size</span><span class=o>=</span><span class=mi>64</span><span class=p>,</span> <span class=n>shuffle</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>test_loader</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>DataLoader</span><span class=p>(</span><span class=n>test_dataset</span><span class=p>,</span> <span class=n>batch_size</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span> <span class=n>shuffle</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 定义LeNet模型、损失函数和优化器</span>
</span></span><span class=line><span class=cl><span class=n>lenet</span> <span class=o>=</span> <span class=n>LeNet</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>criterion</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>CrossEntropyLoss</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>optimizer</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>optim</span><span class=o>.</span><span class=n>Adam</span><span class=p>(</span><span class=n>lenet</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>lr</span><span class=o>=</span><span class=mf>0.001</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 训练LeNet模型</span>
</span></span><span class=line><span class=cl><span class=n>num_epochs</span> <span class=o>=</span> <span class=mi>10</span>
</span></span><span class=line><span class=cl><span class=n>total_step</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>train_loader</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>epoch</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>num_epochs</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=p>(</span><span class=n>images</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>train_loader</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># 前向传播</span>
</span></span><span class=line><span class=cl>        <span class=n>outputs</span> <span class=o>=</span> <span class=n>lenet</span><span class=p>(</span><span class=n>images</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>loss</span> <span class=o>=</span> <span class=n>criterion</span><span class=p>(</span><span class=n>outputs</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 反向传播及优化</span>
</span></span><span class=line><span class=cl>        <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=p>(</span><span class=n>i</span><span class=o>+</span><span class=mi>1</span><span class=p>)</span> <span class=o>%</span> <span class=mi>100</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span> <span class=p>(</span><span class=s1>&#39;Epoch [</span><span class=si>{}</span><span class=s1>/</span><span class=si>{}</span><span class=s1>], Step [</span><span class=si>{}</span><span class=s1>/</span><span class=si>{}</span><span class=s1>], Loss: </span><span class=si>{:.4f}</span><span class=s1>&#39;</span>
</span></span><span class=line><span class=cl>                   <span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>epoch</span><span class=o>+</span><span class=mi>1</span><span class=p>,</span> <span class=n>num_epochs</span><span class=p>,</span> <span class=n>i</span><span class=o>+</span><span class=mi>1</span><span class=p>,</span> <span class=n>total_step</span><span class=p>,</span> <span class=n>loss</span><span class=o>.</span><span class=n>item</span><span class=p>()))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 测试LeNet模型在测试集上的准确率</span>
</span></span><span class=line><span class=cl><span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=n>correct</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>    <span class=n>total</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>images</span><span class=p>,</span> <span class=n>labels</span> <span class=ow>in</span> <span class=n>test_loader</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>outputs</span> <span class=o>=</span> <span class=n>lenet</span><span class=p>(</span><span class=n>images</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>_</span><span class=p>,</span> <span class=n>predicted</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=n>outputs</span><span class=o>.</span><span class=n>data</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>total</span> <span class=o>+=</span> <span class=n>labels</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>correct</span> <span class=o>+=</span> <span class=p>(</span><span class=n>predicted</span> <span class=o>==</span> <span class=n>labels</span><span class=p>)</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span><span class=o>.</span><span class=n>item</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Accuracy of the model on the 10000 test images: </span><span class=si>{}</span><span class=s1> %&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=mi>100</span> <span class=o>*</span> <span class=n>correct</span> <span class=o>/</span> <span class=n>total</span><span class=p>))</span>
</span></span></code></pre></td></tr></table></div></div><p>在上述代码中，我们首先定义了一个<code>LeNet</code>类，用于实现LeNet模型。该模型包含两个卷积层和三个全连接层，其中第一个卷积层的输入通道数为1，输出通道数为6，卷积核大小为5x5，步长为1；第二个卷积层的输入通道数为6，输出通道数为16，卷积核大小为5x5，步长为1。两个卷积层后接两个最大池化层，窗口大小为2x2，步长为2。其余部分为三个全连接层，分别包含120、84和10个神经元。</p><p>然后，我们定义损失函数为交叉熵损失函数，优化器为随机梯度下降(SGD)算法，并开始训练模型。在训练过程中，我们使用Mini-Batch SGD进行迭代优化，并计算每次迭代的损失值，以便进行模型效果评估。</p><p>最后，我们在测试集上对模型进行测试，并输出预测准确率。</p><a href=#最后补充个常重要的知识点1--1卷积核没错就是宽和的值都为1的卷积核1--1卷积核的使能解决哪些问题><h3 id=最后补充个常重要的知识点1--1卷积核没错就是宽和的值都为1的卷积核1--1卷积核的使能解决哪些问题><span class=hanchor arialabel=Anchor># </span> 最后补充⼀个⾮常重要的知识点："1 * 1卷积核"，没错，就是宽和⾼的值都为1的卷积核。㉕"1 * 1卷积核"的使⽤能解决哪些问题？</h3></a><p>这周内容主要是卷积神经⽹络基础知识，在解决计算机视觉相关问题⼗分重要。</p></article><hr><div class=page-end id=footer><div class=backlinks-container><h3>Backlinks</h3><ul class=backlinks><li>No backlinks found</li></ul></div><div><script src=https://cdn.jsdelivr.net/npm/d3@6.7.0/dist/d3.min.js integrity="sha256-+7jaYCp29O1JusNWHaYtgUn6EhuP0VaFuswhNV06MyI=" crossorigin=anonymous></script><h3>Interactive Graph</h3><div id=graph-container></div><style>:root{--g-node:var(--secondary);--g-node-active:var(--primary);--g-node-inactive:var(--visited);--g-link:var(--outlinegray);--g-link-active:#5a7282}</style><script src=https://www.knowlnk.tech/js/graph.6579af7b10c818dbd2ca038702db0224.js></script></div></div><div id=contact_buttons><footer><p>Made by Wu Chenyue using <a href=https://github.com/jackyzha0/quartz>Quartz</a>, © 2023</p><ul><li><a href=https://www.knowlnk.tech/>Home</a></li><li><a href=https://github.com/rootyue>GitHub</a></li></ul></footer></div></div></body></html>