---
title: "机器学习基础作业班 第三周"
tags:
- 机器学习
---

这次课我们开始说计算机视觉任务⾥的主流技术：卷积神经⽹络。


 ![](res/begin_home_work/week3/image1.png)下⾯是⼀张简笔画图⽚，我知道当你看到这样图⽚的时候能够很快的识别图像⾥⾯是⼀只⼤象。



 有⼈认为，那是因为这张图⾥有两只圆圆⼤⼤的⽿朵、⼀个⻓⻓的⿐⼦、粗壮的四肢和细细的尾巴，在你的经验

  

 ⾥把这四个特征放到⼀起时，是⼤象⽆疑了。

  

 机器是不是也可以先识别这些局部特征再综合判断图中的动物类别？答案是肯定的。下⾯的问题就变成如何能够表示这些特征以及如何能够识别这些特征。

  

 为了解决这个问题，先补充两个知识点：补充1. 图⽚在计算机中的表示⽅式。

  

![](res/begin_home_work/week3/image2.png)



如上图所示，图⽚在机器⾥由很多像素点构成，每个像素点都是取值在\`0-255\`的数值。当图⽚像上图⼀样是⿊⽩图⽚(灰度图⽚)时，每个像素点由⼀个数值构成，上图⼤⼩就是\`1\*18\*18\`；如果图⽚是彩⾊的，每个像素点通常由三个数值构成，分别表示这个点上红绿蓝的强弱，这就是RGB表示⽅式(R-red\\G-green\\B-blue)。为了理解的更清楚，我们再看下图这个例⼦：

  

 ![](res/begin_home_work/week3/image3.png)

  
 彩⾊图⽚中，每个像素点上表示红⾊强弱的数值组合成⼀个矩阵，我们管这个矩阵叫做图⽚的⼀个通道，同理，图⽚的绿⾊蓝⾊也会各⾃构成⼀个矩阵，所以这张彩⾊图⽚具有对应RGB的三个通道，上图⼤⼩就是 3\*8\*6 ( 通道数\*⾼\*宽)。注意，在⽹络中图⽚的⼤⼩通常和输⼊层的⼤⼩密切相关。


 补充2. 图⽚中的特征构成。

  

![](res/begin_home_work/week3/image4.jpeg)

  

###  以上图为例，如果要识别⼈脸通常会先去识别⼀些更⼩的特征，⽐如上例最底图中各种\"边\"，①为什么可以这样做？这样做有什么好处？
> 可以这样子做是因为物体的一些基本特征具有很好的区分度和稳定性。而这样子做的好处是可以提高识别的准确性，将复杂的问题分而治之，降低计算量。


所以现在问题换为在图中识别⼩特征：

"边1"：
 ![](res/begin_home_work/week3/image5.png)


 根据上⾯补充1中内容，"边1"对应矩阵信息表示为：


 ![](res/begin_home_work/week3/image6.png)

 ![](res/begin_home_work/week3/image7.png)现在特征的表示已经有了，如何在图⽚中来识别这些特征？这就是我们⽤的\"卷积\"过程了。现在我在图中找到两个⼦图，\"⼦图1\"以及对应矩阵信息表示为：

 ![](res/begin_home_work/week3/image8.png)为了表示\"⼦图1\"是否是\"边1\"要找的特征，我们进⾏这样的计算：

  

 这⾥的"44500"是计算的结果。 "⼦图2"以及对应矩阵信息表示为：


![](res/begin_home_work/week3/image9.png)
  

### ②按照上⾯的计算⽅法，将\"⼦图2\"与\"边1\"进⾏计算的计算结果应该是？
> 30 x 100+100 x 100=3000+10000=13000
  

### ③将这两个计算结果对⽐，你会发现什么？这说明什么？
> 44500 > 13000 说明子图1比子图2有更大的可能性为边”1”

### ④参考我的视频\"卷积神经⽹络(CNN)卷积过程\"，理解卷积神经⽹络中\"卷积\"的过程具体是怎样的？
在卷积神经网络(Convolutional Neural Network, CNN)中，卷积运算是一种重要的图像处理操作，用于提取输入数据中的特征信息。下面具体介绍卷积过程：

1.  首先确定卷积核的大小和深度(即通道数)，通常是一个小矩阵，如3x3或5x5。卷积核的深度等于输入数据的深度。
2.  将卷积核从输入数据的最左上角位置开始，按照步长(stride)进行滑动，在每个位置上执行卷积运算。
3.  在每个位置上，将卷积核与输入数据的对应部分进行逐元素相乘，并将结果相加得到输出特征图上该位置的值。
4.  重复2-3步骤，直到卷积核滑动完整个输入数据，生成了一个新的输出特征图。

### ⑤视频中选⽤的步⻓为1，如果步⻓为2，有什么意义？
> 步长为1时，卷积核每次沿着输入数据的水平和垂直方向分别移动一个像素。这种方式可以捕获输入数据中更细小的特征，但会生成更大尺寸和更高分辨率的输出特征图。
> 
> 步长为2时，卷积核每次沿着输入数据的水平和垂直方向分别移动两个像素，跳过了一部分输入数据。这种方式可以减少输出特征图的尺寸和分辨率，从而降低模型的计算复杂度，并且可以增强模型的泛化性能。
  

按照这个\"卷积\"过程，由\"边1\"按照步⻓为1在原图中进⾏计算，将计算结果拼成的矩阵叫做\"特征图\"，那么
\"边1\"对应的特征图如下：

  

 ![](res/begin_home_work/week3/image10.png)

  

### ⑥观察上例\"特征图\"，\"特征图\"和\"边1\"是什么关系？如何理解\"特征图\"？
> 特征图就是”边1”在滑动的过程中对应位置上的可能性。而”特征图”就是经过卷积核操作后提取出来的更高层次的特征表示，每一个特征图都对应着一组卷积核的输出结果。

 ![](res/begin_home_work/week3/image11.png)如果现在有\"边1\"、\"边2\"和\"边3\"，就会得到三个\"特征图\"(如下图)，通常为了表述清楚我们说这⾥得到的是⼀个\"特征图\"，⼀个具有三通道的\"特征图\"(只是我个⼈的表述习惯)。

  

 像这⾥的\"边1\"这样⽤来表示某个\"特征\"的元素就是\"卷积核\"。

  

###  ![](res/begin_home_work/week3/image12.png)⑦卷积核的数量和特征图\"通道数\"间有什么关系？注意：卷积核也是可以多个通道的，如下图：
> 卷积核的数量和特征图的”通道数”是保持一致的


这⾥是⼀个卷积核，⼀个具有三通道的卷积核，最终获得了⼀个通道的特征图。


### ⑧请⽤你的理解解释上图。
> 原图有三个通道的数据，使用了具有三个通道的卷积核，每一个通道的数据使用了对应层的卷积核进行操作分别得到对应的临时特征图，而这3个临时特征图可以合并为一个具有3通道的特征图。

### ⑨如果希望对彩⾊图⽚(RGB)进⾏\"卷积\"后得到多个通道的特征图，需要怎么做？
> 可以对其应用多通道的卷积核进行操作

### ⑩假如有⼀张⼤⼩为12px\*12px⼤⼩的png图⽚，⽤2个3\*3⼤⼩的卷积核处理，在步⻓为1的情况下，得到的特征图形状(⼤⼩)为？(注意:应当表示为\"通道数\*⾼\*宽 \")
> 2 x 10 x10

### ⑪请总结输⼊图⽚的通道数、卷积核的通道数、卷积核的数量和输出特征图的通道数之间是怎样的关系。
> 输入图片的通道数和卷积核的通道数保持一致，卷积核的数量和输出特征图的通道数保持一致

### ⑫经常会在卷积之后加上\"池化\"操作，\"池化\"的意义是什么？
> 池化操作就是一个没有可习得的参数的卷积核操作，池化的意义就是可以进行下采样

### ⑬常⻅到的池化有\"最⼤池化\"和\"平均池化\"，请举例说明分别如何计算。
“最大池化”在当前卷积核大小中取的当前区域范围内的最大值，而 “平均池化” 则是求得当前范围内的平均值。

池化层的步长(stride)决定了池化窗口在输入数据上移动的距离。最大池化(Max Pooling)和平均池化(Average Pooling)的滑动步长都可以是任意正整数，但通常选择的步长为池化窗口的大小的一半，即 $stride = \frac{pool\_size}{2}$。

这样的步长选择有以下原因：

1.  保证没有重叠区域：使用步长为池化窗口大小的一半，可以确保每个池化窗口之间不存在重叠区域，避免了类似于卷积操作中的局部重叠现象，从而减少输出特征图的尺寸和计算量。
2.  避免信息丢失：使用过大的步长会使得池化操作忽略一些重要的特征信息，从而影响模型的性能和鲁棒性。使用步长为池化窗口大小的一半，可以保证池化操作不会过于粗略，同时也不会过度压缩特征信息。
  

### ⑭在卷积和池化的时候经常先给图⽚进⾏\"填充\"，常⻅到的填充⽅式有哪些？填充的意义是什么？
在卷积神经网络(Convolutional Neural Network, CNN)中，卷积和池化操作通常都需要将输入数据进行填充(padding)，以控制输出特征图的尺寸、边缘效应等。下面是一些常见的填充方式及其意义：

1.  零填充(Zero Padding)：零填充是最常用的一种填充方式，在输入数据的周围添加一圈值为0的像素，使得原始输入数据和填充后的数据尺寸相同。零填充的主要作用是保持输入数据的空间大小不变，并且可以减少边缘效应的影响，从而提高模型的准确性和鲁棒性。
2.  边界填充(Border Padding)：边界填充是在输入数据的四周添加与边缘颜色相同的像素，一般情况下会使用黑色或白色像素进行填充。这种填充方式可以避免由于零填充引入的额外噪声和干扰，但同时也会导致输出特征图的尺寸比输入数据更小。
3.  反射填充(Reflect Padding)：反射填充是在输入数据的边缘上按照对称镜像的方式添加像素，使得输入数据和输出数据具有相同的尺寸和形状。反射填充可以有效地避免边缘效应，并且可以保留输入数据的平滑性和连续性，从而提高模型的稳定性和可靠性。
4.  复制填充(Copy Padding)：复制填充是将输入数据的边缘像素复制若干次，使得输入数据和填充后的数据具有相同的尺寸。这种填充方式可以避免边缘效应，但同时也可能会引入额外的重复信息和噪声，从而影响模型的性能和鲁棒性。

填充的主要作用是控制输出特征图的尺寸，比如说可以保持处理后的特征图和原图的尺寸一致。
  

### ⑮输⼊图⽚⾼宽、输出特征图⾼宽、卷积核⾼宽、步⻓和填充⼤⼩之间有怎样的关系？
out_height = (input_height + 2 x padding_height - kernel_height) / stride + 1
out_width = (input_width + 2 x padding_width - kernel_width) / stride + 1

现在，你已经对卷积神经⽹络⾥⾯的基本概念有所了解，可以尝试思考回答以下较为深⼊的问题。

### ⑯如何理解卷积过程中的\"平移不变性\"？
> “平移不变性”指在进行卷积核操作的时候是进行滑动计算的，所以就算特征发生了平移的情况也可以找到对应的特征。

### ⑰为什么说卷积神经⽹络是\"稀疏连接\"的？
> 因为卷积核进行计算的时候是进行滑动且一一对应的，所以对应到神经网络节点的连接上去就是稀疏的

### ⑱如何理解卷积过程中的\"参数共享\"？
> 卷积神经网络在进行连接的时候是稀疏连接的，而卷积核操作需要使用固定的卷积核参数进行计算，所以卷积核上的位置对应的连接权重是相同的，这个就是”参数共享”

  
最最最最最最最最最最最最最重要的问题来了：
  

![](res/begin_home_work/week3/image13.png)

  

别告诉我你没⻅过，这是LeNet⽹络结构图，是卷积神经⽹络的⿐祖。

### ⑲ 如果卷积核是代表的图中局部小特征，那么如何找到这里面的填充值？
> 这部分的填充值是需要在投喂数据的时候进行训练的，是网络自己习得的。

### ⑳ 在今天学习的内容里面，哪些是在卷积神经网络里的超参数？
> 超参数是网络自身无法习得的参数，比如说网络的连接结构，卷积核的大小，卷积核操作时的步长以及填充方式和大小。

### ㉑请你看图解释这个⽹络的设计(别着急查资料，先⾃⼰读图试试，都是我们学习过的内容)。
> 先是32x32的图片输入，经过一次卷积核操作（6@5x5）得到6@28x28的特征图，再进行一次池化操作（下采样，卷积核为 6@2x2）得到6@14x14特征图，在进行一次卷积核操作（16@5x5）得到16@10x10的特征图，再进行一次池化操作（下采样，卷积核为16@6x6）得到16@5x5的特征图，然后展开通过一层全连接达到C5，一次全连接达到F6，最后使用softmax分类器进行多分类，输出概率最大的类别
  

### 读懂⽹络结构图之后，就⽤代码去实现吧，像搭积⽊⼀样，把对应的功能封装成函数后拼装在⼀起，这⾥⾯⽤到了全连接层、卷积层和池化层和激活函数。我们之前定义过激活函数，㉒你完全可以⾃⼰实现⼀个卷积函数和⼀个池化函数（选做）。当然，这只是为了练习和学习，通常使⽤时会直接调⽤框架中给我们提供的接⼝。
 
### ㉓PyTorch中的卷积层和池化层应当如何调⽤函数实现？如何设置窗⼝⼤⼩、填充和步⻓？

在PyTorch中，可以使用torch.nn模块中的Conv2d和MaxPool2d类来实现卷积层和池化层，具体的调用方法如下：

1.  Conv2d函数的调用方法：

```python
import torch.nn as nn

# 定义一个卷积层，输入特征图通道数为in_channels，输出特征图通道数为out_channels，卷积核大小为kernel_size，步长为stride，填充方式为padding
conv_layer = nn.Conv2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding)

```

2. MaxPool2d函数的调用方法：

```python
import torch.nn as nn

# 定义一个池化层，窗口大小为kernel_size，步长为stride，填充方式为padding
pool_layer = nn.MaxPool2d(kernel_size, stride=stride, padding=padding)

```

其中，in_channels和out_channels分别表示输入和输出特征图的通道数；kernel_size表示卷积核或池化窗口的大小；stride表示卷积或池化操作时在输入数据上移动的步长；padding表示在输入数据周围添加的额外像素。

例如，可以定义一个卷积层，它的输入特征图通道数为3，输出特征图通道数为16，卷积核大小为3x3，步长为1，填充方式为1，代码如下：

```python
import torch.nn as nn
conv_layer = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)
```

也可以定义一个最大池化层，它的窗口大小为2x2，步长为2，填充方式为0，代码如下：

```python
import torch.nn as nn
pool_layer = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)
```

通过这些方法可以轻松地实现卷积和池化操作，并且可以根据需要设置窗口大小、填充和步长等超参数。

### ㉔组件都会⽤了，你可以尝试使⽤PyTorch将这个LeNet⽹络的定义实现。

```python
import torch
import torch.nn as nn
import torchvision
import torchvision.transforms as transforms

# 定义LeNet模型
class LeNet(nn.Module):
    def __init__(self):
        super(LeNet, self).__init__()
        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)
        self.sigm1 = nn.Sigmoid()
        self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2)
        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)
        self.sigm2 = nn.Sigmoid()
        self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2)
        self.fc1 = nn.Linear(16 * 5 * 5, 120)
        self.sigm3 = nn.Sigmoid()
        self.fc2 = nn.Linear(120, 84)
        self.sigm4 = nn.Sigmoid()
        self.fc3 = nn.Linear(84, 10)

    def forward(self, x):
        x = self.pool1(self.sigm1(self.conv1(x)))
        x = self.pool2(self.sigm2(self.conv2(x)))
        x = x.view(-1, 16 * 5 * 5)
        x = self.sigm3(self.fc1(x))
        x = self.sigm4(self.fc2(x))
        x = self.fc3(x)
        return x

# 加载MNIST数据集
transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])
train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)
test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100, shuffle=False)

# 定义LeNet模型、损失函数和优化器
lenet = LeNet()
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(lenet.parameters(), lr=0.001)

# 训练LeNet模型
num_epochs = 10
total_step = len(train_loader)
for epoch in range(num_epochs):
    for i, (images, labels) in enumerate(train_loader):
        # 前向传播
        outputs = lenet(images)
        loss = criterion(outputs, labels)

        # 反向传播及优化
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        if (i+1) % 100 == 0:
            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'
                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))

# 测试LeNet模型在测试集上的准确率
with torch.no_grad():
    correct = 0
    total = 0
    for images, labels in test_loader:
        outputs = lenet(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

    print('Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))


```

在上述代码中，我们首先定义了一个`LeNet`类，用于实现LeNet模型。该模型包含两个卷积层和三个全连接层，其中第一个卷积层的输入通道数为1，输出通道数为6，卷积核大小为5x5，步长为1；第二个卷积层的输入通道数为6，输出通道数为16，卷积核大小为5x5，步长为1。两个卷积层后接两个最大池化层，窗口大小为2x2，步长为2。其余部分为三个全连接层，分别包含120、84和10个神经元。

然后，我们定义损失函数为交叉熵损失函数，优化器为随机梯度下降(SGD)算法，并开始训练模型。在训练过程中，我们使用Mini-Batch SGD进行迭代优化，并计算每次迭代的损失值，以便进行模型效果评估。

最后，我们在测试集上对模型进行测试，并输出预测准确率。

###  最后补充⼀个⾮常重要的知识点：\"1 \* 1卷积核\"，没错，就是宽和⾼的值都为1的卷积核。㉕\"1 \* 1卷积核\"的使⽤能解决哪些问题？



这周内容主要是卷积神经⽹络基础知识，在解决计算机视觉相关问题⼗分重要。

