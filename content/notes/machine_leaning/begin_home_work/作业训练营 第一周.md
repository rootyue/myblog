---
title: "机器学习基础作业班 第一周"
tags:
- 机器学习
---

## 理论部分

### 1. 请你来尝试回答，在机器利⽤鸢尾花数据集对鸢尾花进⾏分类任务的学习过程中，三要素分别对应什么？

> T：对给定的单个鸢尾花数据（萼片长度、萼片宽度、花瓣长度、花瓣宽度）预测对应的标签值（类别）
> 
> E：150个鸢尾花数据样本（萼片长度、萼片宽度、花瓣长度、花瓣宽度）和对应的标签数据（类别）
> 
> P指标：对给定的鸢尾花数据（萼片长度、萼片宽度、花瓣长度、花瓣宽度）预测对应的标签值（类别））的准确度

### 2. 如何理解“使⽤机器学习解决问题的⽬的是为了获得⼀个复杂函数”这句话？

> 用计算机解决问题可以看成是用 已知的信息 进行计算最终可以得到 需要的信息，也就是 F(已知信息) = 需要的信息
> 所以机器学习的过程可以理解为 可以从 经验E 中让学习系统去调整 函数F(已知信息) = 需要的信息 黑箱中的系数，让 P指标 也就是 函数F(已知信息) 结果的准确度更高

### 3. 请分别以⼿写数字识别数据集（MNIST）和鸢尾花数据集（iris）为例解释以下相关概念：样本、特征、特征取值、特征向量、特征维数；类别与类别标签、训练集、测试集、验证集。
> 样本是指被观察或研究对象的个体，MNIST手写数字识别数据集的样本是各种手写数字图片，特征是每个图片中每个像素点的灰度值，特征取值为0~255，特征向量是包含所有像素点灰度值的向量，特征维数为784（28x28）。
> MNIST 手写数字识别数据集的类别是数字 0~9，共有 10 类。类别标签是数字数组，取值范围为 0~9，与图像一一对应。训练集包含 60,000 幅图像，用于神经网络模型学习。测试集包含 10,000 幅图像，用于评估模型的识别准确率。针对 MNIST 数据集，将训练集的 60,000 幅图像分成 50,000 幅训练图像和 10,000 幅验证图像。验证集可以用于调整神经元网络中的超参数，如学习速率等。
> 鸢尾花数据集有150个样本，每个样本都是一个鸢尾花植物，包括萼片、花瓣等部位的测量结果。特征是指描述每个样本的属性，鸢尾花数据集的特征包括萼片长度、萼片宽度、花瓣长度和花瓣宽度。特征取值是指每个特征对应的值，这些值可以是实数或整数等多种类型，具体取决于样本的属性。特征向量是指将每个样本的特征按一定顺序组成的向量，鸢尾花数据集的特征向量长度为4，分别对应每个特征的值。特征维数是指特征向量的长度或者枚举类型的种类数，鸢尾花数据集的特征维数为4，即每个样本有4个特征。
> 鸢尾花数据集包括150个样本，每个样本对应一朵鸢尾花，其中记录了萼片长度、萼片宽度、花瓣长度和花瓣宽度等特征。每个样本属于3种不同的鸢尾花品种之一，分别为Setosa、Versicolor和Virginica。这些品种被称为鸢尾花数据集的类别标签。
> 在对该数据集进行机器学习任务时，通常会将这些数据划分为三个部分：训练集、验证集和测试集。其中训练集用于训练模型，验证集用于为模型选择超参数和对模型进行评估，最后测试集用于评估模型的最终性能。具体划分比例可以根据具体情况进行设置。

### 4. "识别或预测给定的⼿写体数字图像的类别"是⼀个典型的分类任务，除此之外，机器学习常⻅的学习任务还包括“回归”、“聚类”、“特征降维”等，请分别举例解释说明。
> 分类：如果最后的预测结果是离散且有限的，那么就是分类任务，比如说识别人像照片是男是女。
> 回归：如果最后的预测结果会是连续的，那么就是回归问题，比如说线性回归，需要用一条直线来拟合测试数据。
> 聚类：是给定的数据没有标签的情况下，根据数据的特点（比如说在所在空间的距离）自进行类别划分。
> 特征降维：对训练数据进行学习时，数据的维度越大那么学习和训练的难度也就越大，可以将多维数据转换为带有其中要特征的低维数据的过程就是数据降维。

### 5. 举例解释监督学习、⽆监督学习（⾮监督学习）和强化学习分别是怎样的学习范式。
> 监督学习：提供给学习系统的数据是带有预先标注好的信息的（标签），也就是我们需要预测得到的信息。
> 无监督学习：提供给学习系统的数据是没有预先标注的信息，需要学习系统自己从中学习数据之间的规律与特征。
> 强化学习：引入了奖励函数，如果做对了某一些事情就可以得分，这个算引入了“人在回路”的学习

### 6. 让机器进⾏学习前需要先确定三件事： 1. 选择⼀个具有未知参数的模型；2. 定义损失函数；3. 确定优化⽅法。之后便根据优化⽅法开始训练模型，直⾄达到预期标准后，将训练好的模型进⾏保存，就可以⽤它对未知数据进⾏预测了。这个过程具体是怎样的？请举例详尽说明。
> 1：选择⼀个具有未知参数的模型其实也就是根据需要解决的问题，选择合适的模型结构（超参数），而此时的模型中参数是未知的
> 2：定义损失函数就是用来度量模型预测值和真实值差异程度的非负实数函数，用来评价当前模型预测的准确程度
> 3：确定优化⽅法就是确定使用哪些优化模型的算法，根据损失函数变化的程度来确定如何去调整模型中的参数

### 7. 经常⽤“⽋拟合”和“过拟合”来对模型性能进⾏评价，请举例解释这两个概念。
> 比如说用神经网络来拟合一些点，欠拟合就相当于是当前神经网络生成的曲线在训练数据上都没有很好的拟合。而过拟合就相当于是很好的拟合了训练数据，但是是以蜿蜒曲折的曲线进行拟合的，并没有学习到一般的规律。

### 8. 请举例说明如何基于交叉验证进⾏模型的选择与评价？
> 有两种交叉验证模型的方法，一个是 K折交叉验证，一个是重复的K折验证。
>  K折交叉验证：是一种评估机器学习模型性能的方法。它将可用数据划分为K个互不重叠的子集，每次用K-1个子集作为训练集，剩下的那个子集作为验证集，这样就可获得K个训练/测试集。最终返回的是这K个测试结果的均值。这种方法可以评估模型的泛化性能，避免验证集和测试集过小造成的方差小或者过大。
>  重复的K折验证：它是对K折交叉验证方法的改进，特别适用于可用数据相对较少的情况。在重复的K折验证中，使用K折验证方法来多次对数据进行分割和评估，最终的评估结果是每次K折验证结果的平均值。它通常会先将数据随机打乱，然后进行多次K折验证来提高评估结果的准确性。

## 编程部分

###  1. NumPy 、  Pandas 、  Matplotlib 分别通常⽤来解决什么样的问题。
> Numpy 是用来解决矩阵运算的，Pandas很像表格数据，可以用来进行查询，而Matplotlib可以进行图表的绘制

###  2. NumPy 和  Pandas 中的数据类型是什么。
> Numpy中的数据类型是 NDArray，而Pandas中的数据是DataFrame 还有 Series（DataFrame可以看成是多个Series组成的字典）

###  3. NumPy 的  ndarray 和  Python 中的原⽣数组之间有什么区别？
> ndarray 底层运算是在GPU中运行的，而原生数组是在cpu中运行。同时ndarray支持的切片操作有很多种，而Python中的原生数组只支持下标切片。而且ndarray还支持广播操作还有一个常用的函数操作。

###   4. NumPy 的多维数组创建⽅式分别是如何使⽤的。
#### np.array() 
> np.array() 在使用时值需要传入一个序列型的数据，就可以得到对应的ndarray序列

#### np.ones() ， np.zeros() 和 np.empty()
> 使用方法是一样的：1.传入一个数字代表着一维数据的元素个数。2. 传入 [x1,x2,...,xn]序列数据可以指定每一维数据的数量进行创建。
> 不同之处在于ones创建的ndarray中每一个元素值都是1，zeros创建的都是0，而empty创建的元素值是没有初始化的

#### np.arange()
> np.arange可以指定开始值，结束值以及步长得到一个一维的ndarray序列

#### np.ones_like() 和 np.zeros_like()
> 都可以传入一个原生多维数组或者ndarray生成一个对应维度的ndarray，不过ndarray中的每一个元素都会分别变成1（前者）,0（后者）

#### np.random.random()
> 可以传入size表示需要生成的ndarray数组的维度，数组中的每一个元素的数值为0到1之间的随机小数

### 5. 已知有数据：    a = np.arange(25).reshape(5, 5)
问题1：交换2⾏和3⾏，交换4列和5列
```python
前者是 a[[1,2]] = a[[2,1]] ，后者是 a[:,[3,4]] = a[:, [4,3]]
```

问题2：将所有奇数替换为-1 
```python
a[c % 2 == 1] = -1
```

问题3：将对⻆线上的值替换为0
```python
idx = np.diag_indices(5)
a[idx]=0
```

### 6. 使⽤  Numpy 创建⼀个  5\*5 的矩阵，每⾏数值都是从  0-4
```python
np.arange(0,5) * np.ones([5,5])
```

### 7. 从⼆维数组  a_2d = np.array(\[\[3,3,3],\[4,4,4],\[5,5,5]]) 中的每⾏减去⼀维数组  b_1d = np.array(\[1,2,3]) 中相应的值？
```python
a_2d - b_1d
```

### 8. 创建⼀个形状为（6，4）的  NumPy 随机数组，⽤该数组创建⼀个列名为['A', 'B', 'C', 'D']的  DataFrame 。
```python
r = np.random.random([6,4])
df = pd.DataFrame(r, dolumns=['A', 'B', 'C', 'D'])
```

### 9. 已知有⼀个Python字典存储了3位同学的4⻔课成绩，课程分别是'C, Java, Python, JS',请创建DataFrame来 显示成绩单。字典如下：
```python
d = {
	'LiYongzhu' : [95, 96, 90, 88], 'LiuQingyuan' : [90, 93, 95, 90], 'GuoYimeng' : [100, 100, 100, 100]
}
df = pd.DataFrame(d)
```


### 10. 根据  babynames 数据集，解决以下问题：
A. 分别统计男⽣和⼥⽣的出⽣⼈数
```python
import os

# 设置数据集所在目录和文件名前缀
data_dir = "dataset/names"
prefix = "yob"

# 存储男生和女生的数量
male_count = 0
female_count = 0

# 遍历目录中所有符合条件的文件
for filename in os.listdir(data_dir):
    if filename.startswith(prefix):
        # 打开文件并逐行读取数据
        with open(os.path.join(data_dir, filename), "r") as f:
            data = f.readlines()
            for line in data:
                # 解析每一行数据，获取性别和出生人数
                name, gender, count = line.strip().split(",")
                if gender == "M":
                    male_count += int(count)
                elif gender == "F":
                    female_count += int(count)

# 输出男生和女生的数量
print("Male count:", male_count)
print("Female count:", female_count)
```

B. 有多少个不重复的名字
```python
import os

# 设置数据集所在目录和文件名前缀
data_dir = "dataset/names"
prefix = "yob"

# 存储所有不重复的名字
unique_names = set()

# 遍历目录中所有符合条件的文件
for filename in os.listdir(data_dir):
    if filename.startswith(prefix):
        # 打开文件并逐行读取数据
        with open(os.path.join(data_dir, filename), "r") as f:
            data = f.readlines()
            for line in data:
                # 解析每一行数据，获取姓名并添加到集合中
                name, _, _ = line.strip().split(",")
                unique_names.add(name)

# 输出不重复的名字数量
print("Number of unique names:", len(unique_names))
```

C. 横坐标为年份，纵坐标为数量，男⼥不同的⾛势图
```python
import os
import matplotlib.pyplot as plt

# 设置数据集所在目录和文件名前缀
data_dir = "dataset/names"
prefix = "yob"

# 存储男生和女生每年的出生人数
male_counts = {}
female_counts = {}

# 遍历目录中所有符合条件的文件
for filename in os.listdir(data_dir):
    if filename.startswith(prefix):
        # 解析文件名，获取年份
        year = int(filename[3:-4])

        # 打开文件并逐行读取数据
        with open(os.path.join(data_dir, filename), "r") as f:
            data = f.readlines()
            for line in data:
                # 解析每一行数据，获取性别和出生人数
                name, gender, count = line.strip().split(",")
                if gender == "M":
                    if year not in male_counts:
                        male_counts[year] = 0
                    male_counts[year] += int(count)
                else:
                    if year not in female_counts:
                        female_counts[year] = 0
                    female_counts[year] += int(count)

# 整理数据，生成绘图所需的 X 和 Y 坐标
x = list(male_counts.keys())
y_male = list(male_counts.values())
y_female = list(female_counts.values())

# 绘制男女数量走势图
plt.plot(x, y_male, label="Male")
plt.plot(x, y_female, label="Female")
plt.xlabel("Year")
plt.ylabel("Count")
plt.title("Number of Births by Gender and Year")
plt.legend()
plt.show()
```

### 11. 根据  drinks 数据集，解决以下问题：
A. 哪个国家的饮酒量最⼤
```python
import pandas as pd  
  
# 读取数据集  
drinks = pd.read_csv('dataset/drinks.csv')
rank = drinks.groupby('country')['total_litres_of_pure_alcohol'].sum().sort_values(ascending=False)

print("饮酒量最⼤的国家是：", rank.index[0])
```


B. 哪个⼤洲的饮酒量最⼤
```python
import pandas as pd

# 读取数据集
drinks = pd.read_csv("dataset/drinks.csv")

# 按照大陆对总消耗量进行分组求和，并排序
continent_drinks = drinks.groupby('continent')['total_litres_of_pure_alcohol'].sum().sort_values(ascending=False)

# 输出饮酒量最大的大洲
print("饮酒量最大的大洲是：", continent_drinks.index[0])

```
